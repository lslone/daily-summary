# Name the components on this agent
a1.sources = r1
a1.sinks = k1 k2
a1.channels = c1
a1.sinkgroups = g1

# Describe/configure the source
#source type 声明
a1.sources.r1.type = org.keedio.flume.source.SQLSource
#被采集数据源
a1.sources.r1.hibernate.connection.url = jdbc:mysql://192.168.11.72:3306/test
a1.sources.r1.hibernate.connection.user = root
a1.sources.r1.hibernate.connection.password = introcks1234
a1.sources.r1.hibernate.connection.autocommit = true
a1.sources.r1.table = user
a1.sources.r1.columns.to.select = user
a1.sources.r1.hibernate.dialect = org.hibernate.dialect.MySQLDialect
a1.sources.r1.hibernate.connection.driver_class = com.mysql.jdbc.Driver
# Query delay, each configured milisecond the query will be sent
a1.sources.r1.run.query.delay = 10000
# Status file is used to save last readed row
a1.sources.r1.status.file.path = /home/hadoop/flume-1.8.0/sql.source
a1.sources.r1.status.file.name = sql.source.status
#从id为0的记录开始查询，注意：flume-ng-sql-source 的记录标识为id
a1.sources.r1.start.from = 0
# 自定义查询语句
a1.sources.r1.custom.query = select id, name, age from user where id > $@$


# set sink1
a1.sinks.k1.type = avro
a1.sinks.k1.hostname = ds074
a1.sinks.k1.port = 52020

# set sink2
a1.sinks.k2.type = avro
a1.sinks.k2.hostname = ds075
a1.sinks.k2.port = 52020

# Use a channel which buffers events in memory
a1.channels.c1.type = memory
a1.channels.c1.capacity = 10000
a1.channels.c1.transactionCapacity = 1000

#set sink group
a1.sinkgroups.g1.sinks = k1 k2
#set failover
a1.sinkgroups.g1.processor.type = failover
a1.sinkgroups.g1.processor.priority.k1 = 10
a1.sinkgroups.g1.processor.priority.k2 = 1
a1.sinkgroups.g1.processor.maxpenalty = 10000

# Bind the source and sink to the channel
a1.sources.r1.channels = c1
a1.sinks.k2.channel = c1
a1.sinks.k1.channel = c1